---
title: "CPEAT 875 datasets ingestion"
author: "Vaasuki Marupaka"
date: "2023-06-20"
output: html_document
---

```{r}
# install.packages('pangaear')
# install.packages('dplyr')
library(tidyverse)
library(pangaear) # see package details at https://github.com/ropensci/pangaear
library(dplyr) # set of tools for data manipulation, see details at https://dplyr.tidyverse.org/

#=============== 1. SEARCH (by PROJECT) and download citations =================
# Documentation of PANGAEA search: https://wiki.pangaea.de/wiki/PANGAEA_search
# Website: https://www.pangaea.de/?q=project:label:PAGES_C-PEAT
# search with pg_search: maximum = 500 records (set with count, continue with offset to add additional record beyond 500) 
# 2022-11: There are 875 datasets PUBLISHED
#PAGES <- pg_search("project:label:PAGES_C-PEAT", count = 500)

# download all dataset citations:
# rbind function: joins 2 or more dataframes
#PAGES <- rbind(PAGES, pg_search("project:label:PAGES_C-PEAT", count = 500, offset = 500))
# create a column with full citations
#PAGES$fullcitation <- paste0(PAGES$citation, ". PANGAEA, https://doi.org/", PAGES$doi)

pages.df <- pg_search("project:label:PAGES_C-PEAT", count = 500) %>% 
  bind_rows(pg_search("project:label:PAGES_C-PEAT", count = 500, offset = 500)) %>% #the output will contain all columns that appear in any of the inputs
  mutate(fullcitation = paste0(citation, ". PANGAEA, https://doi.org/", doi)) #%>% # adds additional column 
 #mutate(fullDOI = paste0("PANGAEA, https://doi.org/", doi))


#PAGES_Geochemistry <- filter(PAGES, grepl("Geochemistry", citation))

#PAGES_AgeDetermination <- filter(PAGES, grepl("Age determinatio", citation))

#PAGES_CalibratedAges <- filter(PAGES, grepl("Calibrated ages", citation))

```


```{r}
#=============== 2. SETTING PANGAEAR CACHE ===================
# why is this relevant? pg_data automatically writes the .tab file to the cache folder, so it is nice to have it "at hand", See 3. GET DATA
# check the location of the cache path for pangaear
pg_cache$cache_path_get()


# create a folder for download - a warning appears if the directory already exists
#getwd()
#dir.create(path=paste0(getwd(),"/Downloads"))
#folderpath <- (paste0(getwd(),"/Downloads"))

folderpath <- (file.path(getwd(),"Downloads")) # used file.path function

# set the location of the cache path for pangaear 
pg_cache$cache_path_set(full_path = folderpath)
# now data files are downloaded into that folder when executing pg_data()

```


```{r}

#Pull into a list, all the data from the files the specified dois in the search results 
allData.ls <- plyr::dlply(pages.df, #search results
                          c("doi"), #grouping on unique identifer
                          .fun = function(xx) { #defining our fetch function
                            #the pg_data returns a list of a single item, remove that from the parent list
                            return(pg_data(doi = xx$doi, overwrite = FALSE)[[1]])
                          }) 

#Pull the core information by accessing the data item in the lists
allCores.df <- plyr::ldply(allData.ls, .fun = function(xx) {
  print(xx$doi)
  if(xx$doi %in% c("10.1594/PANGAEA.934281")){
    names(xx$data)[10] <- 'Age unc [±] (Age, tephra-chronostratigraphy, calculated, 1 sigma)'
  }
  
   if(xx$doi %in% c("10.1594/PANGAEA.934343")){
     names(xx$data)[9] <- 'Age unc [±] (Age, tephra-chronostratigraphy, calculated, 1 sigma)'
   }
  
  if(xx$doi %in% c("10.1594/PANGAEA.941094")){
     names(xx$data)[10] <- 'Age [a AD/CE] alt.'
  }
  
  if(xx$doi %in% c("10.1594/PANGAEA.929068")){
    names(xx$data)[5:7] <- paste(names(xx$data)[5:7], 'alt.') #true replicates??
  }

  if(identical(names(xx$data)[c(2:4, 6:8)], 
                    c("Cal age [ka BP] (Median Age, Age, 14C calibrat...)", 
                    "Cal age max [ka BP] (Age, 14C calibrated, OxCal 4....)",
                    "Cal age min [ka BP] (Age, 14C calibrated, OxCal 4....)",
                    "Cal age [ka BP] (Median Age, Age, 14C calibrat...)",
                    "Cal age max [ka BP] (Age, 14C calibrated, Bacon 2....)",
                    "Cal age min [ka BP] (Age, 14C calibrated, Bacon 2....)")) |
     xx$doi %in% c("10.1594/PANGAEA.929655")){
    names(xx$data)[c(2:4, 6:8)] <- c(
                        'Cal age [ka BP] (Median Age, 14C calibrated, OxCal 4.2.4)', 
                        'Cal age max [ka BP] (Age, 14C calibrated, OxCal 4.2.4)', 
                        'Cal age min [ka BP] (Age, 14C calibrated, OxCal 4.2.4)',
                        'Cal age [ka BP] (Median Age, 14C calibrated, Bacon 2.2)', 
                        'Cal age max [ka BP] (Age, 14C calibrated, Bacon 2.2)', 
                        'Cal age min [ka BP] (Age, 14C calibrated, Bacon 2.2)') #add the methods that are dropped here
  }
  
  if(identical(names(xx$data)[2:7], 
                    c("Cal age [ka BP] (Median Age, Age, 14C calibrat...)", 
                    "Cal age max [ka BP] (Age, 14C calibrated, OxCal 4....)",
                    "Cal age min [ka BP] (Age, 14C calibrated, OxCal 4....)",
                    "Cal age [ka BP] (Median Age, Age, 14C calibrat...)",
                    "Cal age max [ka BP] (Age, 14C calibrated, Bacon 2....)",
                    "Cal age min [ka BP] (Age, 14C calibrated, Bacon 2....)")) |
     xx$doi %in% c("10.1594/PANGAEA.930030")){
    
    names(xx$data)[2:7] <- c(
                        'Cal age [ka BP] (Median Age, 14C calibrated, OxCal 4.2.4)', 
                        'Cal age max [ka BP] (Age, 14C calibrated, OxCal 4.2.4)', 
                        'Cal age min [ka BP] (Age, 14C calibrated, OxCal 4.2.4)',
                        'Cal age [ka BP] (Median Age, 14C calibrated, Bacon 2.2)', 
                        'Cal age max [ka BP] (Age, 14C calibrated, Bacon 2.2)', 
                        'Cal age min [ka BP] (Age, 14C calibrated, Bacon 2.2)') #add the methods that are dropped here
  }
  
  
  if(length(names(xx$data)) > length(unique(names(xx$data)))){
    print(names(xx$data))
  }
  return(mutate(.data = xx$data, across(.cols = everything(),  as.character)))
}) 

#Pull the study information
allStudy.df <- plyr::ldply(allData.ls, .fun = function(xx) {
  #list out all the possible names for the study info, be sure to update
  #...this list manually if the warning is thrown.
  primaryNames <- intersect(names(xx), c('parent_doi', 'doi', 'citation', 
                                         'url', 'path'))
  
  #There shouldn't be any names that we don't include above.
  if(any( ! (names(xx) %in% c(primaryNames, 'metadata', 'data')))){
    warning(paste('possible missing informatin at primary level for', xx$doi,
                  setdiff(names(xx), c(primaryNames, 'metadata', 'data'))))
  }
  
  #access the study information in the primary list
  ans.ls <- xx[primaryNames]
  
  #deal with the information in the metadata, again we name each possible
  #...list item here and if there are new names this needs to be updated.
  metaNames <- intersect(names(xx$metadata), c("citation", "related_to", "further_details",
                                               "projects" , "coverage",
                                               "abstract", "keywords",
                                               "status",
                                               "license", "size", "comment"))
  if(any( ! (names(xx$metadata) %in% c(metaNames, 'events', 'parameters')))){
    warning(paste('possible missing informatin at metadata level for', xx$doi))
  }
  
  #append the metadata items to the items from the primary list
  ans.ls <- c(ans.ls, xx$metadata[metaNames])
  
  #Pull in the study information from the 'events' item in the list
  #...again there should be no items that are not matching the manual array here
  eventsNames <- intersect(names(xx$metadata$events), c("LATITUDE", "LONGITUDE",
                                                         "ELEVATION", "ELEVATION START", "ELEVATION END",
                                                         "Penetration", "Recovery",
                                                         "LOCATION", "METHOD/DEVICE", 
                                                         "COMMENT"))
  
  #Take out the first item of the list which is actually the core name itself.
   if(any( ! (names(xx$metadata$events)[-1] %in%  
              c("LATITUDE", "LONGITUDE", "ELEVATION",
                "ELEVATION START", "ELEVATION END", 
                "Penetration","Recovery",
                "LOCATION", "METHOD/DEVICE", "COMMENT")))){
    warning(paste('possible missing informatin at metadata-events level for', xx$doi))
   }
   
  #The core name is a special case where the information is in the name and not
  #...in the list values. Deal with that and append the events information.
   ans.ls <- c(list(core_name = names(xx$metadata$events)[1]),
               ans.ls, 
               xx$metadata$events[eventsNames])
   
  # change everything to a data frame to make it easier to read
  return(as.data.frame(ans.ls, stringsAsFactors = FALSE))
})


allParameters.df <-  plyr::ldply(allData.ls, .fun = function(xx) {
  
  if(xx$doi %in% c("10.1594/PANGAEA.934281")){
    names(xx$data)[10] <- 'Age unc [±] (Age, tephra-chronostratigraphy, calculated, 1 sigma)'
  }
  
   if(xx$doi %in% c("10.1594/PANGAEA.934343")){
     names(xx$data)[9] <- 'Age unc [±] (Age, tephra-chronostratigraphy, calculated, 1 sigma)'
   }
  
  if(xx$doi %in% c("10.1594/PANGAEA.941094")){
     names(xx$data)[10] <- 'Age [a AD/CE] alt.'
   }
  
  colHeader <- names(xx$data)
  colDescript <- unlist(lapply(xx$metadata$parameters, paste, collapse = " "))
  
  if(xx$doi == "10.1594/PANGAEA.934274"){
    colDescript <- c(colDescript[1:4], 
                     paste(colDescript[5], ';', colDescript[6]),
                     colDescript[7:9])
  }
  
  #pull the parameter descriptions in and append them to the headers in the data
  ParametersGeo <- data.frame(header = colHeader, 
                              description = colDescript, 
                              stringsAsFactors = FALSE) %>%
    #add in a column index
    mutate(column_index = 1:ncol(xx$data))
  
  return(ParametersGeo)
})


```


```{r}
#loop for the Age determination classification 
#PAGES_AgeDetermination_data <- data.frame()
#my_all_names <- c()

temp_AgeD <- plyr::ddply(PAGES_AgeDetermination, c("doi","citation"), .fun = function(xx) {
  all_AgeD_data <- pg_data(doi = xx$doi, overwrite = FALSE) # difficult to interpret if using the clumn indexing with number 
  all_AgeD_data <- all_AgeD_data[[1]]$data
  # add columns identifying unique source of data for further attribution
  return(all_AgeD_data)
}) 


# for (i in 1:nrow(PAGES_AgeDetermination)) { # tried with smaller dataset from 32:64 rows earlier
#   # using pg_data will automatically download the .tab format of the datasets (metadata + data) in the cache folder
#   all_AgeD_data <- pg_data(doi=PAGES_AgeDetermination[i,2])
#   print(all_AgeD_data)
#  # print(pg_data(doi=PAGES_AgeDetermination[i,2])) # this was adding more time to run
#   print(i)
#   all_AgeD_data <- all_AgeD_data[[1]]$data
#   #if (is.numeric(all_AgeD_data$`Lab label`)) {
#    #all_AgeD_data <- rename(all_AgeD_data, `Lab label(chr)` = `Lab label`)
#   #}
#   # add columns identifying unique source of data for further attribution
#   all_AgeD_data$DOI <- as.character(PAGES_AgeDetermination[i,2])
#   all_AgeD_data$citation <- as.character(PAGES_AgeDetermination[i,5])
#   my_all_names <- union(my_all_names, names(all_AgeD_data))
#   #print(names(all_AgeD_data))
#   #PAGES_AgeDetermination_data <- bind_rows(PAGES_AgeDetermination_data, all_AgeD_data)
# }

# renaming columns probably might not help
# compare the column names across the datasets! <- ignore 
# look up names repair function in r
# look into ldply function [get rid of for loop]
# create a test data frame or tibble with two columns with the same name [maybe 3*3], use name_repair function to fix that -> to give an integer to the same name column  
# try applying it to line 83 if it works 
# try to find where the code is slow, and look for optimization 



write.table(PAGES_AgeDetermination_data, file=paste0(datapath,"PAGES_AgeDetermination_CPEAT.txt"), row.names = FALSE, quote = FALSE, sep = "\t", na = "")


allAgeData.ls <- plyr::dlply(PAGES_AgeDetermination[1:nrow(PAGES_AgeDetermination),], c("doi"), .fun = function(xx) {
  all_Age_data <- pg_data(doi = xx$doi, 
                          overwrite = FALSE) # difficult to interpret if using the column indexing with number 
  all_Age_data <- all_Age_data[[1]]
  # add columns identifying unique source of data for further attribution
  return(all_Age_data)
}) 

all_Age_Cores.df <- plyr::ldply(allAgeData.ls, .fun = function(xx) {
  return(xx$data)
}) 


all_Age_Study.df <- plyr::ldply(allAgeData.ls, .fun = function(xx) {
  primaryNames <- intersect(names(xx), c('parent_doi', 'doi', 'citation', 
                                         'url', 'path'))
  if(any( ! (names(xx) %in% c(primaryNames, 'metadata', 'data')))){
    warning(paste('possible missing informatin at primary level for', xx$doi,
                  setdiff(names(xx), c(primaryNames, 'metadata', 'data'))))
  }
  ans.ls <- xx[primaryNames]
  
  metaNames <- intersect(names(xx$metadata), c("citation", "related_to", "further_details",
                                               "projects" , "coverage",
                                               "abstract", "keywords",
                                               "status",
                                               "license", "size", "comment"))
   if(any( ! (names(xx$metadata) %in% c(metaNames, 'events', 'parameters')))){
    warning(paste('possible missing informatin at metadata level for', xx$doi))
   }
   ans.ls <- c(ans.ls, xx$metadata[metaNames])
  
   eventsNames <- intersect(names(xx$metadata$events), c("LATITUDE", "LONGITUDE",
                                                         "ELEVATION", "ELEVATION START", "ELEVATION END",
                                                         "Penetration", "Recovery",
                                                         "LOCATION", "METHOD/DEVICE", 
                                                         "COMMENT"))
   if(any( ! (names(xx$metadata$events)[-1] %in%  
              c("LATITUDE", "LONGITUDE", "ELEVATION",
                "ELEVATION START", "ELEVATION END", 
                "Penetration","Recovery",
                "LOCATION", "METHOD/DEVICE", "COMMENT")))){
    warning(paste('possible missing informatin at metadata-events level for', xx$doi))
   }
   
   ans.ls <- c(list(core_name = names(xx$metadata$events)[1]),
               ans.ls, 
               xx$metadata$events[eventsNames])
   
  # add columns identifying unique source of data for further attribution
  return(as.data.frame(ans.ls, stringsAsFactors = FALSE))
})


test <- data.frame(header = names(allAgeData.ls[['10.1594/PANGAEA.890189']]$data), description = unlist(lapply(allAgeData.ls[['10.1594/PANGAEA.890189']]$metadata$parameters, paste, collapse = " ")), 
                    allAgeData.ls[['10.1594/PANGAEA.890189']]$doi)


# Something is wrong with the code base that each time it runs into an error
all_AgeParameters.df <-  plyr::ldply(allAgeData.ls, .fun = function(xx) {
             ParametersAge <- data.frame(header = names(xx$data), 
            description = unlist(lapply(xx$metadata$parameters, paste, collapse = " "))) 
            if(any( ! (names(xx$data) %in% 
                        names(xx$metadata$parameters)))){
                          warning(paste("Data and parameters lengths differ.", xx$doi))
                        }
})



```


```{r}
#loop for the Calibrated Age classification 
#PAGES_CalibratedAges_data <- data.frame()

# for (i in 1:nrow(PAGES_CalibratedAges)) {
#   # using pg_data will automatically download the .tab format of the datasets (metadata + data) in the cache folder
#   all_CalAge_data <- pg_data(doi=PAGES_CalibratedAges[i,2])
#   print(all_CalAge_data)
#   print(i)
#   all_CalAge_data <- all_CalAge_data[[1]]$data
#   # add columns identifying unique source of data for further attribution
#   all_CalAge_data$DOI <- as.character(PAGES_CalibratedAges[i,2])
#   all_CalAge_data$citation <- as.character(PAGES_CalibratedAges[i,5])
#   PAGES_CalibratedAges_data <- as.data.frame(bind_rows(PAGES_CalibratedAges_data, all_CalAge_data))
# }

write.table(PAGES_CalibratedAges_data, file=paste0(datapath,"PAGES_CalibratedAges_CPEAT.txt"), row.names = FALSE, quote = FALSE, sep = "\t", na = "")

temp_CalAge <- plyr::ddply(PAGES_CalibratedAges, c("doi","citation"), .fun = function(xx) {
  all_CalAge_data <- pg_data(doi = xx$doi, overwrite = FALSE) # difficult to interpret if using the clumn indexing with number 
  all_CalAge_data <- all_CalAge_data[[1]]$data
  # add columns identifying unique source of data for further attribution
  return(all_CalAge_data)
}) 

# NEW CODE 
all_CalData.ls <- plyr::dlply(PAGES_CalibratedAges[1:nrow(PAGES_CalibratedAges),], c("doi"), .fun = function(xx) {
  all_CalAge_data <- pg_data(doi = xx$doi, 
                          overwrite = FALSE) # difficult to interpret if using the column indexing with number 
  all_CalAge_data <- all_CalAge_data[[1]]
  # add columns identifying unique source of data for further attribution
  return(all_CalAge_data)
}) 

all_Cal_Cores.df <- plyr::ldply(all_CalData.ls, .fun = function(xx) {
  return(xx$data)
}) 


all_Cal_Study.df <- plyr::ldply(all_CalData.ls, .fun = function(xx) {
  primaryNames <- intersect(names(xx), c('parent_doi', 'doi', 'citation', 
                                         'url', 'path'))
  if(any( ! (names(xx) %in% c(primaryNames, 'metadata', 'data')))){
    warning(paste('possible missing informatin at primary level for', xx$doi,
                  setdiff(names(xx), c(primaryNames, 'metadata', 'data'))))
  }
  ans.ls <- xx[primaryNames]
  
  metaNames <- intersect(names(xx$metadata), c("citation", "related_to", "further_details",
                                               "projects" , "coverage",
                                               "abstract", "keywords",
                                               "status",
                                               "license", "size", "comment"))
   if(any( ! (names(xx$metadata) %in% c(metaNames, 'events', 'parameters')))){
    warning(paste('possible missing informatin at metadata level for', xx$doi))
   }
   ans.ls <- c(ans.ls, xx$metadata[metaNames])
  
   eventsNames <- intersect(names(xx$metadata$events), c("LATITUDE", "LONGITUDE",
                                                         "ELEVATION", "ELEVATION START", "ELEVATION END",
                                                         "Penetration", "Recovery",
                                                         "LOCATION", "METHOD/DEVICE", 
                                                         "COMMENT"))
   if(any( ! (names(xx$metadata$events)[-1] %in%  
              c("LATITUDE", "LONGITUDE", "ELEVATION",
                "ELEVATION START", "ELEVATION END", 
                "Penetration","Recovery",
                "LOCATION", "METHOD/DEVICE", "COMMENT")))){
    warning(paste('possible missing informatin at metadata-events level for', xx$doi))
   }
   
   ans.ls <- c(list(core_name = names(xx$metadata$events)[1]),
               ans.ls, 
               xx$metadata$events[eventsNames])
   
  # add columns identifying unique source of data for further attribution
  return(as.data.frame(ans.ls, stringsAsFactors = FALSE))
})


```



# LET US TRY MAKING SOME COOL PLOTS!!! - LOCATIONS 
```{r}

# Locations for calibrated ages data plotting

all_Cal_Study.df$LATITUDE <- as.numeric(all_Cal_Study.df$LATITUDE)
all_Cal_Study.df$LONGITUDE <- as.numeric(all_Cal_Study.df$LONGITUDE)

LOCATION <- all_Cal_Study.df %>%
          select(LATITUDE, LONGITUDE, LOCATION) %>%
 filter(is.finite(!is.na(LATITUDE) + is.na(LONGITUDE)))

ggplot() +
  geom_polygon(data = map_data('world'), aes(x = long, y = lat, group = group), fill = "lightgray") +
  geom_point(data = LOCATION, aes(x = LONGITUDE, y = LATITUDE), color = "green", size = 2) +
  labs(x = "Longitude", y = "Latitude") +
  ggtitle("Latitude and Longitude Points on World Map")


# Locations for GEOCHEMISTRY data plotting

allStudy.df$LATITUDE <- as.numeric(allStudy.df$LATITUDE)
allStudy.df$LONGITUDE <- as.numeric(allStudy.df$LONGITUDE)

LOCATION <- allStudy.df %>%
          select(LATITUDE, LONGITUDE, LOCATION) %>%
 filter(is.finite(!is.na(LATITUDE) + is.na(LONGITUDE)))

ggplot() +
  geom_polygon(data = map_data('world'), aes(x = long, y = lat, group = group), fill = "lightgray") +
  geom_point(data = LOCATION, aes(x = LONGITUDE, y = LATITUDE), color = "blue", size = 2) +
  labs(x = "Longitude", y = "Latitude") +
  ggtitle("Latitude and Longitude Points on World Map")


# Locations for AGE DETERMINATION data plotting

all_Age_Study.df$LATITUDE <- as.numeric(all_Age_Study.df$LATITUDE)
all_Age_Study.df$LONGITUDE <- as.numeric(all_Age_Study.df$LONGITUDE)

LOCATION <- all_Age_Study.df %>%
          select(LATITUDE, LONGITUDE, LOCATION) %>%
 filter(is.finite(!is.na(LATITUDE) + is.na(LONGITUDE)))

ggplot() +
  geom_polygon(data = map_data('world'), aes(x = long, y = lat, group = group), fill = "lightgray") +
  geom_point(data = LOCATION, aes(x = LONGITUDE, y = LATITUDE), color = "red", size = 2) +
  labs(x = "Longitude", y = "Latitude") +
  ggtitle("Latitude and Longitude Points on World Map")


```

# LET US MAKE PLOTS FOR THE DEPTH 
```{r}

# Depths for CALIBRATED AGES data plotting
Depth <- all_Cal_Cores.df %>%
          select(`Depth sed [m]`) %>%
 filter(is.finite(!is.na(`Depth sed [m]`)))


# NEEDS A LOT OF WORK!!!
ggplot(data = Depth)
   geom_histogram(aes(x = `Depth sed [m]`))  #make a histrogram
  #facet_wrap(~variable,scales = 'free')




```



```{r}
# write citations as txt file
write.table(sort(PAGES$fullcitation), file="citations_pages.txt", row.names = FALSE, col.names = FALSE, quote = FALSE, sep = "\t", na = "")
```





