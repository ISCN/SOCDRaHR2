# Vogel

```{r warning=FALSE, message=FALSE}
datasetName <- 'Vogel'

##### Extract the study information ####
dataset_study <- citation_raw %>% 
  filter(dataset_name == datasetName) %>%
  select(where(function(xx){!all(is.na(xx))})) %>%
  full_join(dataset_raw %>% 
              filter(dataset_name == datasetName) %>%
              select(where(function(xx){!all(is.na(xx))})), suffix = c('_citation', '_dataset'))%>%
  standardCast() %>%
  fill(everything(), .direction = "downup") %>%  #fills gaps in citation
  mutate(`modification_date (YYYY-MM-DD)` = "2009-12-05") %>% #hardcode modification date to all match, removing excess column
  unique()
```

```{r warning=FALSE, message=FALSE}
##### Extract the profile information ####

#comparison for pre ISCN soc stock correction
dataset_profile_org <- profile_raw  %>%
   filter(dataset_name_sub == datasetName) %>%
   standardCast()

dataset_profile <- profile_raw  %>%
  filter(dataset_name_sub == datasetName) 

if(any(grepl('ISCN', dataset_profile$dataset_name_soc))){
  #reassign rows where the ISCN tried to fill in SOC values
  dataset_profile <- dataset_profile %>%
    group_by(dataset_name_soc) %>%
    mutate(`soc_depth (cm)` = if_else(grepl('ISCN', dataset_name_soc),
                                      rep(NA_character_, length(`soc_depth (cm)`)), `soc_depth (cm)`),
           `soc (g cm-2)` = if_else(grepl('ISCN', dataset_name_soc),
                                    rep(NA_character_, length(`soc (g cm-2)`)), `soc (g cm-2)`),
           soc_carbon_flag = if_else(grepl('ISCN', dataset_name_soc),
                                     rep(NA_character_, length(soc_carbon_flag)), soc_carbon_flag),
           soc_spatial_flag = if_else(grepl('ISCN', dataset_name_soc),
                                      rep(NA_character_, length(soc_spatial_flag)), soc_spatial_flag),
           soc_method = if_else(grepl('ISCN', dataset_name_soc), 
                                rep(NA_character_, length(soc_method)), soc_method)) %>%
    ungroup()
  
}

#remove the soc dataset since we've taken care of the ISCN notation
dataset_profile <- select(dataset_profile, -dataset_name_soc)  

if(any(count(dataset_profile, dataset_name_sub, site_name, profile_name)$n > 1)){
  #if the rows are duplicated then fill in missing values by group
  dataset_profile <- dataset_profile %>%
    group_by(dataset_name_sub, site_name, profile_name) %>%
    mutate_at(vars(-group_cols()), 
              function(xx){ifelse(sum(!is.na(xx)) == 1, rep(xx[!is.na(xx)], length(xx)),xx)}) %>% #if there is one value that isn't na then populate the rest of the entry, this fills in the
    ungroup() %>%
    unique() #collapase rows that are non-unique
}

dataset_profile <- standardCast(dataset_profile)
```

```{r warning = FALSE, message = FALSE}
##### Extract the layer infromation ####

#comparison before SOC correction
dataset_layer_org <- layer_raw %>%
  filter(dataset_name_sub == datasetName) %>%
  standardCast()

dataset_layer <- layer_raw %>%
  filter(dataset_name_sub == datasetName) 

if(any(grepl('ISCN', dataset_layer$dataset_name_soc))){
  #reassign rows where the ISCN tried to fill in SOC values
  dataset_layer <- dataset_layer %>%
    group_by(dataset_name_soc) %>%
    mutate(`soc (g cm-2)` = if_else(grepl('ISCN', dataset_name_soc),
                                    rep(NA_character_, length(`soc (g cm-2)`)), `soc (g cm-2)`),
           soc_carbon_flag = if_else(grepl('ISCN', dataset_name_soc),
                                     rep(NA_character_, length(soc_carbon_flag)), soc_carbon_flag),
           soc_method = if_else(grepl('ISCN', dataset_name_soc), 
                                rep(NA_character_, length(soc_method)), soc_method)) %>%
    ungroup()
  
}

#remove the soc dataset since we've taken care of the ISCN notation
dataset_layer <- select(dataset_layer, -dataset_name_soc) 

if(any(count(dataset_layer, dataset_name_sub, site_name, profile_name, layer_name)$n > 1)){
  #if the rows are duplicated then fill in missing values by group
  dataset_layer <- dataset_layer %>%
    group_by(dataset_name_sub, site_name, profile_name, layer_name) %>%
    mutate_at(vars(-group_cols()), 
              function(xx){ifelse(sum(!is.na(xx)) == 1, rep(xx[!is.na(xx)], length(xx)),xx)}) %>% #if there is one value that isn't na then populate the rest of the entry, this fills in the
    ungroup() %>%
    unique() #collapase rows that are non-unique
}

dataset_layer <- standardCast(dataset_layer)

```

The `Vogel` data set in ISCN3 contains `r nrow(dataset_layer)` layer-level information and `r nrow(dataset_profile)` profile-level information after cleaning for ISCN3.5.
ISCN3 removed repeated information in citations, which was corrected and filled for ISCN3.5.
ISCN3 also filled in the soil carbon stocks where bulk density and organic carbon was provided, this was removed for ISCN3.5.
This data set was set in Alaska, so the Alaska Location code from the Template was used instead of the generic.

```{r message=FALSE, warning=FALSE}
knitr::kable(t(dataset_study))
```


There are the following factors in the profile:
```{r}
knitr::kable(summary(dataset_profile %>% select_if(is.factor)))
```

And the following factors in the layers:
```{r}
knitr::kable(summary(dataset_layer %>% select_if(is.factor)))
```


##Location

```{r}

country <- ggplot2::map_data('world2', 'usa')
avgLat <- dataset_layer %>% 
  pull('lat (dec. deg)') %>%
  mean()

avgLong <- dataset_layer %>% 
  pull('long (dec. deg)') %>%
  mean() + 360

ggplot(data =  map_data("world2")) +
  geom_polygon( aes(x = long, y = lat, group = group),
                fill = 'grey', color = "black") +
  geom_polygon(data = country, aes(x = long, y = lat, group = group),
                fill = 'lightblue', color = 'black') +
  geom_point(data = dataset_profile, aes(x = avgLong, y = avgLat), shape = 'x', color = 'red', size = 5) +
  coord_cartesian(xlim=c(avgLong - 65, avgLong + 65), ylim = c(avgLat - 25, avgLat + 25)) +
  theme_nothing() +
  labs(title = 'Profile data')

ggplot(data =  map_data("world2")) + 
  geom_polygon(aes(x=long, y = lat, group = group), 
               fill = 'grey', color = 'black') + 
  geom_polygon(data = country, aes(x = long, y = lat, group = group),
                fill = 'lightblue', color = "black") +
  geom_point(data = dataset_layer, aes(x = `long (dec. deg)` + 360, y = `lat (dec. deg)`),
             shape = 'x', color = 'red', size = 2.5) +
  coord_cartesian(xlim=c(avgLong - 9.1, avgLong + 9.1), ylim = c(avgLat - 3.5, avgLat + 3.5)) +
  theme_nothing() +
  labs(title = 'Layer data')
  
```






```{r}
#this is useful to see for the analysis but we don't want it in the report
#create a table that displays the names of the number and factor columns in the dataset, how many values there are in each, and how many unique values there are
dataset_layer %>% #pipe dataset_layer
  pivot_longer(cols = intersect(names(.), type_cols$num_cols), values_drop_na = TRUE) %>% #indicating what values will be used on plots and drop all NA values
  group_by(name) %>% summarize(n = length(value), unique_n = length(unique(value))) %>% #find how many total values and unique values each number column has
  bind_rows( #combine the number and factor column summaries into one dataframe
    dataset_layer %>% #pipe dataset_layer
      pivot_longer(cols = intersect(names(.), type_cols$factor_cols), values_drop_na = TRUE) %>% #indicating what values will be used on plots and drop all NA values
      group_by(name) %>% summarize(n = length(value), unique_n = length(unique(value))) ) %>% #find how many total values and unique values each factor column has
  arrange(n) %>%
  knitr::kable() #create the table
```

## Profile histograms

```{r}
##using profile data to create a histogram for each measured variable in this data set
ggplot(dataset_profile %>%
         pivot_longer(cols = intersect(names(.), type_cols$num_cols), #selecting what columns to pull
                      values_to = 'measurement', names_to = 'type')) + #naming x values and the variables to make histograms of
  geom_histogram(aes(x=measurement)) +  #setting x and y axes
  facet_wrap(~type, scales='free') +
  theme_bw() #using a compatible theme with histogram function
```

## Depth plots

```{r}
##using layer data to create a plot for each measured variable at corresponding depths in this data set
ggplot(dataset_layer %>% 
         pivot_longer( cols=c('layer_top (cm)', 'layer_bot (cm)'),
                       values_to='depth') %>% 
         pivot_longer(cols = intersect(names(.), type_cols$num_cols), 
                      values_to = 'measurement', names_to = 'type')) + #indicating what values will be used on plots
         geom_line(aes(x=depth, y= measurement, group = profile_name), alpha = 0.5) + #assigning which sets of values will be on x and y axes
  facet_wrap(~type, scales='free') +
  theme_bw()
```
## TODO

- Find out where temperature and precipitation data is (currently not on ISCN)

#### Github issue template

- [ ]  External review by someone else

## Citations

Please see @Kane2009; @Vogel2007; @Vogel2008 for additional details and if you are using ISCN3 please cite.